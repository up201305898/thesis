{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notebook for streaming data from a microphone in realtime\n",
    "\n",
    "audio is captured using pyaudio\n",
    "then converted from binary data to ints using struct\n",
    "then displayed using matplotlib\n",
    "\n",
    "scipy.fftpack computes the FFT\n",
    "\n",
    "if you don't have pyaudio, then run\n",
    "\n",
    ">>> pip install pyaudio\n",
    "\n",
    "note: with 2048 samples per chunk, I'm getting 20FPS\n",
    "when also running the spectrum, its about 15FPS\n",
    "\"\"\"\n",
    "\n",
    "import pyaudio\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "import time\n",
    "from tkinter import TclError\n",
    "\n",
    "# to display in separate Tk window\n",
    "%matplotlib tk\n",
    "\n",
    "# constants\n",
    "CHUNK = 1024 * 2             # samples per frame\n",
    "FORMAT = pyaudio.paInt16     # audio format (bytes per sample?)\n",
    "CHANNELS = 1                 # single channel for microphone\n",
    "RATE = 44100                 # samples per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream started\n",
      "stream stopped\n",
      "average frame rate = 16 FPS\n"
     ]
    }
   ],
   "source": [
    "# create matplotlib figure and axes\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(15, 7))\n",
    "\n",
    "# pyaudio class instance\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# stream object to get data from microphone\n",
    "stream = p.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    output=True,\n",
    "    frames_per_buffer=CHUNK\n",
    ")\n",
    "\n",
    "# variable for plotting\n",
    "x = np.arange(0, 2 * CHUNK, 2)       # samples (waveform)\n",
    "xf = np.linspace(0, RATE, CHUNK)     # frequencies (spectrum)\n",
    "\n",
    "# create a line object with random data\n",
    "line, = ax1.plot(x, np.random.rand(CHUNK), '-', lw=2)\n",
    "\n",
    "# create semilogx line for spectrum\n",
    "line_fft, = ax2.semilogx(xf, np.random.rand(CHUNK), '-', lw=2)\n",
    "\n",
    "# format waveform axes\n",
    "ax1.set_title('AUDIO WAVEFORM')\n",
    "ax1.set_xlabel('samples')\n",
    "ax1.set_ylabel('volume')\n",
    "ax1.set_ylim(0, 255)\n",
    "ax1.set_xlim(0, 2 * CHUNK)\n",
    "plt.setp(ax1, xticks=[0, CHUNK, 2 * CHUNK], yticks=[0, 128, 255])\n",
    "\n",
    "# format spectrum axes\n",
    "ax2.set_xlim(20, RATE / 2)\n",
    "\n",
    "print('stream started')\n",
    "\n",
    "# for measuring frame rate\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # binary data\n",
    "    data = stream.read(CHUNK)  \n",
    "    \n",
    "    # convert data to integers, make np array, then offset it by 127\n",
    "    data_int = struct.unpack(str(2 * CHUNK) + 'B', data)\n",
    "    \n",
    "    # create np array and offset by 128\n",
    "    data_np = np.array(data_int, dtype='b')[::2] + 128\n",
    "    \n",
    "    line.set_ydata(data_np)\n",
    "    \n",
    "    # compute FFT and update line\n",
    "    yf = fft(data_int)\n",
    "    line_fft.set_ydata(np.abs(yf[0:CHUNK])  / (128 * CHUNK))\n",
    "    \n",
    "    # update figure canvas\n",
    "    try:\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        frame_count += 1\n",
    "        \n",
    "    except TclError:\n",
    "        \n",
    "        # calculate average frame rate\n",
    "        frame_rate = frame_count / (time.time() - start_time)\n",
    "        \n",
    "        print('stream stopped')\n",
    "        print('average frame rate = {:.0f} FPS'.format(frame_rate))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BS daqui para baixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-l] [-d DEVICE] [-w DURATION] [-i INTERVAL]\n",
      "                             [-b BLOCKSIZE] [-r SAMPLERATE] [-n N]\n",
      "                             [CHANNEL [CHANNEL ...]]\n",
      "ipykernel_launcher.py: error: argument CHANNEL: invalid int value: 'C:\\\\Users\\\\pedro\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-2c3fdea2-a6ea-42f7-bde4-f7b87c7480ec.json'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"Plot the live microphone signal(s) with matplotlib.\n",
    "\n",
    "Matplotlib and NumPy have to be installed.\n",
    "\n",
    "\"\"\"\n",
    "import argparse\n",
    "import queue\n",
    "import sys\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "\n",
    "\n",
    "def int_or_str(text):\n",
    "    \"\"\"Helper function for argument parsing.\"\"\"\n",
    "    try:\n",
    "        return int(text)\n",
    "    except ValueError:\n",
    "        return text\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(add_help=False)\n",
    "parser.add_argument(\n",
    "    '-l', '--list-devices', action='store_true',\n",
    "    help='show list of audio devices and exit')\n",
    "args, remaining = parser.parse_known_args()\n",
    "if args.list_devices:\n",
    "    print(sd.query_devices())\n",
    "    parser.exit(0)\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=__doc__,\n",
    "    formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "    parents=[parser])\n",
    "parser.add_argument(\n",
    "    'channels', type=int, default=[1], nargs='*', metavar='CHANNEL',\n",
    "    help='input channels to plot (default: the first)')\n",
    "parser.add_argument(\n",
    "    '-d', '--device', type=int_or_str,\n",
    "    help='input device (numeric ID or substring)')\n",
    "parser.add_argument(\n",
    "    '-w', '--window', type=float, default=200, metavar='DURATION',\n",
    "    help='visible time slot (default: %(default)s ms)')\n",
    "parser.add_argument(\n",
    "    '-i', '--interval', type=float, default=30,\n",
    "    help='minimum time between plot updates (default: %(default)s ms)')\n",
    "parser.add_argument(\n",
    "    '-b', '--blocksize', type=int, help='block size (in samples)')\n",
    "parser.add_argument(\n",
    "    '-r', '--samplerate', type=float, help='sampling rate of audio device')\n",
    "parser.add_argument(\n",
    "    '-n', '--downsample', type=int, default=10, metavar='N',\n",
    "    help='display every Nth sample (default: %(default)s)')\n",
    "args = parser.parse_args(remaining)\n",
    "if any(c < 1 for c in args.channels):\n",
    "    parser.error('argument CHANNEL: must be >= 1')\n",
    "mapping = [c - 1 for c in args.channels]  # Channel numbers start with 1\n",
    "q = queue.Queue()\n",
    "\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"This is called (from a separate thread) for each audio block.\"\"\"\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    # Fancy indexing with mapping creates a (necessary!) copy:\n",
    "    q.put(indata[::args.downsample, mapping])\n",
    "\n",
    "\n",
    "def update_plot(frame):\n",
    "    \"\"\"This is called by matplotlib for each plot update.\n",
    "\n",
    "    Typically, audio callbacks happen more frequently than plot updates,\n",
    "    therefore the queue tends to contain multiple blocks of audio data.\n",
    "\n",
    "    \"\"\"\n",
    "    global plotdata\n",
    "    while True:\n",
    "        try:\n",
    "            data = q.get_nowait()\n",
    "        except queue.Empty:\n",
    "            break\n",
    "        shift = len(data)\n",
    "        plotdata = np.roll(plotdata, -shift, axis=0)\n",
    "        plotdata[-shift:, :] = data\n",
    "    for column, line in enumerate(lines):\n",
    "        line.set_ydata(plotdata[:, column])\n",
    "    return lines\n",
    "\n",
    "\n",
    "try:\n",
    "    if args.samplerate is None:\n",
    "        device_info = sd.query_devices(args.device, 'input')\n",
    "        args.samplerate = device_info['default_samplerate']\n",
    "\n",
    "    length = int(args.window * args.samplerate / (1000 * args.downsample))\n",
    "    plotdata = np.zeros((length, len(args.channels)))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    lines = ax.plot(plotdata)\n",
    "    if len(args.channels) > 1:\n",
    "        ax.legend(['channel {}'.format(c) for c in args.channels],\n",
    "                  loc='lower left', ncol=len(args.channels))\n",
    "    ax.axis((0, len(plotdata), -1, 1))\n",
    "    ax.set_yticks([0])\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.tick_params(bottom=False, top=False, labelbottom=False,\n",
    "                   right=False, left=False, labelleft=False)\n",
    "    fig.tight_layout(pad=0)\n",
    "\n",
    "    stream = sd.InputStream(\n",
    "        device=args.device, channels=max(args.channels),\n",
    "        samplerate=args.samplerate, callback=audio_callback)\n",
    "    ani = FuncAnimation(fig, update_plot, interval=args.interval, blit=True)\n",
    "    with stream:\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    parser.exit(type(e).__name__ + ': ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n",
      "finished recording\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    " \n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"file.wav\"\n",
    " \n",
    "audio = pyaudio.PyAudio()\n",
    " \n",
    "# start Recording\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "print (\"recording...\")\n",
    "frames = []\n",
    " \n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "print (\"finished recording\")\n",
    " \n",
    " \n",
    "# stop Recording\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    " \n",
    "waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "waveFile.setnchannels(CHANNELS)\n",
    "waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "waveFile.setframerate(RATE)\n",
    "waveFile.writeframes(b''.join(frames))\n",
    "waveFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please speak a word into the microphone\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-02371e139fc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"please speak a word into the microphone\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[0mrecord_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'demo.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done - result written to demo.wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-02371e139fc1>\u001b[0m in \u001b[0;36mrecord_to_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrecord_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;34m\"Records from the microphone and outputs the resulting data to 'path'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[0msample_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'h'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-02371e139fc1>\u001b[0m in \u001b[0;36mrecord\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_silence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msample_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-02371e139fc1>\u001b[0m in \u001b[0;36madd_silence\u001b[1;34m(snd_data, seconds)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd_silence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msnd_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseconds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;34m\"Add silence to the start and end of 'snd_data' of length 'seconds' (float)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mRATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msnd_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mRATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "THRESHOLD = 500\n",
    "CHUNK_SIZE = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "RATE = 44100\n",
    "\n",
    "def is_silent(snd_data):\n",
    "    \"Returns 'True' if below the 'silent' threshold\"\n",
    "    return max(snd_data) < THRESHOLD\n",
    "\n",
    "def normalize(snd_data):\n",
    "    \"Average the volume out\"\n",
    "    MAXIMUM = 16384\n",
    "    times = float(MAXIMUM)/max(abs(i) for i in snd_data)\n",
    "\n",
    "    r = array('h')\n",
    "    for i in snd_data:\n",
    "        r.append(int(i*times))\n",
    "    return r\n",
    "\n",
    "def trim(snd_data):\n",
    "    \"Trim the blank spots at the start and end\"\n",
    "    def _trim(snd_data):\n",
    "        snd_started = False\n",
    "        r = array('h')\n",
    "\n",
    "        for i in snd_data:\n",
    "            if not snd_started and abs(i)>THRESHOLD:\n",
    "                snd_started = True\n",
    "                r.append(i)\n",
    "\n",
    "            elif snd_started:\n",
    "                r.append(i)\n",
    "        return r\n",
    "\n",
    "    # Trim to the left\n",
    "    snd_data = _trim(snd_data)\n",
    "\n",
    "    # Trim to the right\n",
    "    snd_data.reverse()\n",
    "    snd_data = _trim(snd_data)\n",
    "    snd_data.reverse()\n",
    "    return snd_data\n",
    "\n",
    "def add_silence(snd_data, seconds):\n",
    "    \"Add silence to the start and end of 'snd_data' of length 'seconds' (float)\"\n",
    "    r = array('h', [0 for i in xrange(int(seconds*RATE))])\n",
    "    r.extend(snd_data)\n",
    "    r.extend([0 for i in xrange(int(seconds*RATE))])\n",
    "    return r\n",
    "\n",
    "def record():\n",
    "    \"\"\"\n",
    "    Record a word or words from the microphone and \n",
    "    return the data as an array of signed shorts.\n",
    "\n",
    "    Normalizes the audio, trims silence from the \n",
    "    start and end, and pads with 0.5 seconds of \n",
    "    blank sound to make sure VLC et al can play \n",
    "    it without getting chopped off.\n",
    "    \"\"\"\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=1, rate=RATE,\n",
    "        input=True, output=True,\n",
    "        frames_per_buffer=CHUNK_SIZE)\n",
    "\n",
    "    num_silent = 0\n",
    "    snd_started = False\n",
    "\n",
    "    r = array('h')\n",
    "\n",
    "    while 1:\n",
    "        # little endian, signed short\n",
    "        snd_data = array('h', stream.read(CHUNK_SIZE))\n",
    "        if byteorder == 'big':\n",
    "            snd_data.byteswap()\n",
    "        r.extend(snd_data)\n",
    "\n",
    "        silent = is_silent(snd_data)\n",
    "\n",
    "        if silent and snd_started:\n",
    "            num_silent += 1\n",
    "        elif not silent and not snd_started:\n",
    "            snd_started = True\n",
    "\n",
    "        if snd_started and num_silent > 30:\n",
    "            break\n",
    "\n",
    "    sample_width = p.get_sample_size(FORMAT)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    r = normalize(r)\n",
    "    r = trim(r)\n",
    "    r = add_silence(r, 0.5)\n",
    "    return sample_width, r\n",
    "\n",
    "def record_to_file(path):\n",
    "    \"Records from the microphone and outputs the resulting data to 'path'\"\n",
    "    sample_width, data = record()\n",
    "    data = pack('<' + ('h'*len(data)), *data)\n",
    "\n",
    "    wf = wave.open(path, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(sample_width)\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(data)\n",
    "    wf.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"please speak a word into the microphone\")\n",
    "    record_to_file('demo.wav')\n",
    "    print(\"done - result written to demo.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
